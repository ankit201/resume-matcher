# ============================================
# AI Resume Matcher - Environment Configuration
# ============================================
# Copy this file to .env and fill in your values
# DO NOT commit .env to version control!

# ============================================
# REQUIRED SETTINGS
# ============================================

# Google Gemini API (REQUIRED)
# Get your API key from: https://makersuite.google.com/app/apikey
# Gemini 2.5 Flash tier is currently FREE with generous limits
GOOGLE_API_KEY=your_google_api_key_here

# Gemini Model Selection
# Options: gemini-2.5-flash (recommended), gemini-pro
GEMINI_MODEL=gemini-2.5-flash

# ============================================
# OPTIONAL API KEYS (for comparison/fallback)
# ============================================

# OpenAI API (Optional - for GPT models)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o

# Anthropic API (Optional - for Claude models)
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# ============================================
# APPLICATION SETTINGS
# ============================================

# Environment Mode
# Options: development, production, staging
ENVIRONMENT=development

# Logging Level
# Options: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Maximum Retries for API Calls
MAX_RETRIES=3

# API Timeout (seconds)
TIMEOUT_SECONDS=60

# ============================================
# MATCHING CONFIGURATION
# ============================================

# Semantic Similarity Threshold (0.0 - 1.0)
# Higher = stricter filtering (fewer candidates pass)
# Lower = more lenient (more candidates pass)
# Recommended: 0.7 for balanced filtering
SEMANTIC_THRESHOLD=0.7

# Minimum Match Score (0 - 100)
# Candidates below this score may be flagged
MIN_MATCH_SCORE=60

# ============================================
# SCORING WEIGHTS (must sum to 1.0)
# ============================================
# Adjust these based on your role requirements

# Technical Skills Weight (0.0 - 1.0)
# Default: 0.30 (30%)
# Increase for technical roles, decrease for non-technical
WEIGHT_TECHNICAL_SKILLS=0.30

# Experience Relevance Weight (0.0 - 1.0)
# Default: 0.30 (30%)
# Increase for senior/leadership roles
WEIGHT_EXPERIENCE=0.30

# Education & Certifications Weight (0.0 - 1.0)
# Default: 0.15 (15%)
# Increase if specific degrees/certs are critical
WEIGHT_EDUCATION=0.15

# Cultural Fit & Soft Skills Weight (0.0 - 1.0)
# Default: 0.15 (15%)
# Increase for client-facing or leadership roles
WEIGHT_CULTURAL_FIT=0.15

# Growth Potential Weight (0.0 - 1.0)
# Default: 0.10 (10%)
# Increase for long-term strategic hires
WEIGHT_GROWTH_POTENTIAL=0.10

# ============================================
# COST TRACKING
# ============================================

# Enable API Cost Tracking
TRACK_COSTS=true

# Gemini Cost Per 1K Tokens (USD)
# Flash tier is currently FREE
GEMINI_COST_PER_1K_INPUT=0.00
GEMINI_COST_PER_1K_OUTPUT=0.00

# ============================================
# EMBEDDING MODEL CONFIGURATION
# ============================================

# Sentence Transformer Model
# Options:
#   - sentence-transformers/all-MiniLM-L6-v2 (384 dim, fast, recommended)
#   - sentence-transformers/all-mpnet-base-v2 (768 dim, accurate, slower)
#   - sentence-transformers/paraphrase-MiniLM-L3-v2 (384 dim, fastest, less accurate)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# ============================================
# VECTOR STORE CONFIGURATION
# ============================================

# ChromaDB Persistence Directory
VECTOR_STORE_PATH=./data/vector_store

# Collection Name for Resumes
VECTOR_STORE_COLLECTION=resumes

# ============================================
# ADVANCED SETTINGS (usually don't need to change)
# ============================================

# Enable Bias Detection (experimental)
ENABLE_BIAS_DETECTION=true

# Maximum Resume File Size (MB)
MAX_RESUME_SIZE_MB=10

# Maximum Batch Size (number of resumes)
MAX_BATCH_SIZE=50
